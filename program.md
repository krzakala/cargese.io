![program](front.jpg)

# DAY1: TUESDAY 21

9-12.15: Marc Mezard 

14-17.15: Andrea Montanari [Lecture notes on two-layer neural networks](Montanari.pdf)

# Poster session I (Friday 24)

Samy Jelassi: Smoothed analysis of the low-rank approach for smooth semidefinite programs

Chris Metzler:Unsupervised Learning with Stein's Unbiased Risk Estimator

Marino Raffaele: Revisiting the challenges of MaxClique

Gabriele Sicuro: The fractional matching problem

Dmitriy (Tim) Kunisky: Tight frames, quantum information, and degree 4 sum-of-squares over the hypercube

Benjamin Aubin: Storage capacity in symmetric binary perceptrons

George Stamatescu: Some perspectives on gradient based learning for the binary weight perceptron

Sebastian Goldt: Stochastic Thermodynamics of Learning

Christian Schmidt: estimating symmetric matrices with extensive rank

Adrian Kosowski: Ergodic Effects in Token Circulation

Chan Chun Lam: Adaptive interpolation scheme for inference problems with sparse underlying factor graph

Inbar Seroussi: Phase Transitions in Stochastic Diffusion on a General Network

Jonathan Dong: Optical realization of Echo-State Networks with light-scattering materials

Mihai Nica: Universality of log-normal distribution for randomly initialized neural nets

Andrey Lokhov: Understanding the nature of quantum annealers with statistical learning.

Eric DeGiuli: Random language model -- a path to structured complexity

Grant Rotskoff: Neural networks as interacting particle systems

Thomas Schiex: Exact optimization of pairwise decomposable energy and computational protein design

# Poster session II (Wednesday 29)

Clément Luneau: Entropy of Multilayer Generalized Linear Models: proof of the replica formula with the adaptive interpolation method.

Pan Zhang: Unsupervised Generative Modeling Using Matrix Product States

Andre Manoel: Approximate Message-Passing for Convex Optimization with Non-Separable Penalties

Joris Guerin: Improving Image Clustering With Multiple Pretrained CNN Feature Extractors

Ada Altieri: Constraint satisfaction mechanisms for marginal stability in large ecosystems

Federica Gerace: From statistical inference to a differential learning rule for stochastic neural networks.

Neha Wadia: In Search of Critical Points on Deep Net Optimization Landscapes

Luca Saglietti: Role of synaptic stochasticity in training low-precision neural networks

Carlo Lucibello: Limits of the MAP estimator in the phase retrieval problem

Satoshi Takabe: Trainable ISTA for Sparse Signal Recovery

Antoine Maillard: The committee machine: Computational to statistical gaps in learning a two-layers neural network

Stefano Sarao: Performance of Langevin dynamics in high dimensional inference.

Aurélien Decelle: Thermodynamics properties of restricted boltzmann machines.

Beatriz Seoane Bartolomé: Can a neural network learn a gauge symmetry?

Alia Abbara: Universal transitions in noiseless compressed sensing and phase retrieval

Tomoyuki Obuchi: Accelerating Cross-Validation in Multinomial Logistic Regression with L1-Regularization

# Twitter feed:

<a href="https://twitter.com/intent/tweet?button_hashtag=cargese2018&ref_src=twsrc%5Etfw" class="twitter-hashtag-button" data-show-count="false">Tweet #cargese2018</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

More information on [the institute webpage](http://www.iesc.univ-corse.fr/index.php?id=1&L=1)

![logo](logo.jpg)
